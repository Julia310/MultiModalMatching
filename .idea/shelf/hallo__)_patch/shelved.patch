Index: EmbeddingCreation/createImageEmbedding.py
===================================================================
diff --git a/EmbeddingCreation/createImageEmbedding.py b/EmbeddingCreation/createImageEmbedding.py
--- a/EmbeddingCreation/createImageEmbedding.py	
+++ b/EmbeddingCreation/createImageEmbedding.py	
@@ -56,6 +56,6 @@
             self.db_manager.update_image_by_articleId(embeddings, data_source)
             batch = image_batch_iterator.next_batch()
 
-    def generate_and_save_embeddings(self):
+    def generate_embeddings(self):
         self.process_image_batches(self.image_batch_iterator1, self.data_source1)
         self.process_image_batches(self.image_batch_iterator2, self.data_source2)
Index: EmbeddingCreation/createTextEmbedding.py
===================================================================
diff --git a/EmbeddingCreation/createTextEmbedding.py b/EmbeddingCreation/createTextEmbedding.py
--- a/EmbeddingCreation/createTextEmbedding.py	
+++ b/EmbeddingCreation/createTextEmbedding.py	
@@ -16,7 +16,7 @@
         self.tokenizer = AutoTokenizer.from_pretrained(model_name)
         self.model_name = AutoModel.from_pretrained(model_name)
 
-    def createTextEmbedding(self, text):
+    def create_text_embeddings(self, text):
         encoded_input = self.tokenizer(text, padding=True, truncation=True, return_tensors='pt')
 
         with torch.no_grad():
@@ -37,14 +37,18 @@
         self.data_source2 = data_source2
         self.db_manager = MySQLManager()
 
-    def generate_and_save_embeddings(self):
+    def generate_embeddings(self):
 
         columns = list(self.text_df1.columns)
 
+        cnt = 1
         for (text_df, data_source) in [(self.text_df1, self.data_source1), (self.text_df2, self.data_source2)]:
+            print(f'Starting Data Set ' + str(cnt))
+            cnt += 1
             emb_list = []
-            for i in range(len(columns)):
-                emb_list.append(self.embedding_generator.createTextEmbedding(text=self.text_df1[columns[i]].tolist()))
+            for i in tqdm(range(len(columns)), desc='generate embeddings'):
+                emb_list.append(
+                    self.embedding_generator.create_text_embeddings(text=self.text_df1[columns[i]].tolist()))
             new_columns = ['articleId'] + columns
             self.create_embedding_dicts_from_lists(np.array(text_df.index), new_columns, np.array(emb_list),
                                                    data_source)
@@ -58,4 +62,3 @@
                 values[columns[j + 1]] = row[j].dumps()
             embeddings.append(values)
         self.db_manager.save_many(embeddings, data_source)
-
Index: productMatching.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/productMatching.py b/productMatching.py
--- a/productMatching.py	
+++ b/productMatching.py	
@@ -8,6 +8,9 @@
 
 
 def main():
+
+    print('Start procession')
+
     datasets = preprocess_text_data()
 
     print('Start preparing data for embedding creation')
@@ -19,12 +22,13 @@
 
     print('data prepared for embedding creation in ' + str((time() - start) / 60.0) + ' minutes')
 
-    print('start creating and saving text embeddings')
+    print('start creating text embeddings')
     start = time()
 
     text_to_embeddings_obj = ManageTextEmbeddings('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                                                   text_data_df1, text_data_df2, 'zal', 'th_gw')
-    text_to_embeddings_obj.generate_and_save_embeddings()
+
+    text_to_embeddings_obj.generate_embeddings()
 
     print('text embeddings created and saved in ' + str((time() - start) / 60.0) + ' minutes')
 
@@ -32,7 +36,7 @@
     start = time()
 
     images_to_embeddings = ManageImageEmbeddings(image_list1, image_list2, 'zal', 'th_gw')
-    images_to_embeddings.generate_and_save_embeddings()
+    images_to_embeddings.generate_embeddings()
 
     print('image embeddings created and saved in ' + str((time() - start) / 60.0) + ' minutes')
 
